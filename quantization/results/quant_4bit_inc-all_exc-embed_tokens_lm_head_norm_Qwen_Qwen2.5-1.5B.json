{
  "model": "Qwen/Qwen2.5-1.5B",
  "bits": 4,
  "timestamp": "2025-12-28T06:12:43.529114",
  "layer_config": {
    "include_patterns": null,
    "exclude_patterns": [
      "embed_tokens",
      "lm_head",
      "norm"
    ],
    "quantized_layers": [
      "model.layers.0.self_attn.q_proj",
      "model.layers.0.self_attn.k_proj",
      "model.layers.0.self_attn.v_proj",
      "model.layers.0.self_attn.o_proj",
      "model.layers.0.mlp.gate_proj",
      "model.layers.0.mlp.up_proj",
      "model.layers.0.mlp.down_proj",
      "model.layers.1.self_attn.q_proj",
      "model.layers.1.self_attn.k_proj",
      "model.layers.1.self_attn.v_proj",
      "model.layers.1.self_attn.o_proj",
      "model.layers.1.mlp.gate_proj",
      "model.layers.1.mlp.up_proj",
      "model.layers.1.mlp.down_proj",
      "model.layers.2.self_attn.q_proj",
      "model.layers.2.self_attn.k_proj",
      "model.layers.2.self_attn.v_proj",
      "model.layers.2.self_attn.o_proj",
      "model.layers.2.mlp.gate_proj",
      "model.layers.2.mlp.up_proj",
      "model.layers.2.mlp.down_proj",
      "model.layers.3.self_attn.q_proj",
      "model.layers.3.self_attn.k_proj",
      "model.layers.3.self_attn.v_proj",
      "model.layers.3.self_attn.o_proj",
      "model.layers.3.mlp.gate_proj",
      "model.layers.3.mlp.up_proj",
      "model.layers.3.mlp.down_proj",
      "model.layers.4.self_attn.q_proj",
      "model.layers.4.self_attn.k_proj",
      "model.layers.4.self_attn.v_proj",
      "model.layers.4.self_attn.o_proj",
      "model.layers.4.mlp.gate_proj",
      "model.layers.4.mlp.up_proj",
      "model.layers.4.mlp.down_proj",
      "model.layers.5.self_attn.q_proj",
      "model.layers.5.self_attn.k_proj",
      "model.layers.5.self_attn.v_proj",
      "model.layers.5.self_attn.o_proj",
      "model.layers.5.mlp.gate_proj",
      "model.layers.5.mlp.up_proj",
      "model.layers.5.mlp.down_proj",
      "model.layers.6.self_attn.q_proj",
      "model.layers.6.self_attn.k_proj",
      "model.layers.6.self_attn.v_proj",
      "model.layers.6.self_attn.o_proj",
      "model.layers.6.mlp.gate_proj",
      "model.layers.6.mlp.up_proj",
      "model.layers.6.mlp.down_proj",
      "model.layers.7.self_attn.q_proj",
      "model.layers.7.self_attn.k_proj",
      "model.layers.7.self_attn.v_proj",
      "model.layers.7.self_attn.o_proj",
      "model.layers.7.mlp.gate_proj",
      "model.layers.7.mlp.up_proj",
      "model.layers.7.mlp.down_proj",
      "model.layers.8.self_attn.q_proj",
      "model.layers.8.self_attn.k_proj",
      "model.layers.8.self_attn.v_proj",
      "model.layers.8.self_attn.o_proj",
      "model.layers.8.mlp.gate_proj",
      "model.layers.8.mlp.up_proj",
      "model.layers.8.mlp.down_proj",
      "model.layers.9.self_attn.q_proj",
      "model.layers.9.self_attn.k_proj",
      "model.layers.9.self_attn.v_proj",
      "model.layers.9.self_attn.o_proj",
      "model.layers.9.mlp.gate_proj",
      "model.layers.9.mlp.up_proj",
      "model.layers.9.mlp.down_proj",
      "model.layers.10.self_attn.q_proj",
      "model.layers.10.self_attn.k_proj",
      "model.layers.10.self_attn.v_proj",
      "model.layers.10.self_attn.o_proj",
      "model.layers.10.mlp.gate_proj",
      "model.layers.10.mlp.up_proj",
      "model.layers.10.mlp.down_proj",
      "model.layers.11.self_attn.q_proj",
      "model.layers.11.self_attn.k_proj",
      "model.layers.11.self_attn.v_proj",
      "model.layers.11.self_attn.o_proj",
      "model.layers.11.mlp.gate_proj",
      "model.layers.11.mlp.up_proj",
      "model.layers.11.mlp.down_proj",
      "model.layers.12.self_attn.q_proj",
      "model.layers.12.self_attn.k_proj",
      "model.layers.12.self_attn.v_proj",
      "model.layers.12.self_attn.o_proj",
      "model.layers.12.mlp.gate_proj",
      "model.layers.12.mlp.up_proj",
      "model.layers.12.mlp.down_proj",
      "model.layers.13.self_attn.q_proj",
      "model.layers.13.self_attn.k_proj",
      "model.layers.13.self_attn.v_proj",
      "model.layers.13.self_attn.o_proj",
      "model.layers.13.mlp.gate_proj",
      "model.layers.13.mlp.up_proj",
      "model.layers.13.mlp.down_proj",
      "model.layers.14.self_attn.q_proj",
      "model.layers.14.self_attn.k_proj",
      "model.layers.14.self_attn.v_proj",
      "model.layers.14.self_attn.o_proj",
      "model.layers.14.mlp.gate_proj",
      "model.layers.14.mlp.up_proj",
      "model.layers.14.mlp.down_proj",
      "model.layers.15.self_attn.q_proj",
      "model.layers.15.self_attn.k_proj",
      "model.layers.15.self_attn.v_proj",
      "model.layers.15.self_attn.o_proj",
      "model.layers.15.mlp.gate_proj",
      "model.layers.15.mlp.up_proj",
      "model.layers.15.mlp.down_proj",
      "model.layers.16.self_attn.q_proj",
      "model.layers.16.self_attn.k_proj",
      "model.layers.16.self_attn.v_proj",
      "model.layers.16.self_attn.o_proj",
      "model.layers.16.mlp.gate_proj",
      "model.layers.16.mlp.up_proj",
      "model.layers.16.mlp.down_proj",
      "model.layers.17.self_attn.q_proj",
      "model.layers.17.self_attn.k_proj",
      "model.layers.17.self_attn.v_proj",
      "model.layers.17.self_attn.o_proj",
      "model.layers.17.mlp.gate_proj",
      "model.layers.17.mlp.up_proj",
      "model.layers.17.mlp.down_proj",
      "model.layers.18.self_attn.q_proj",
      "model.layers.18.self_attn.k_proj",
      "model.layers.18.self_attn.v_proj",
      "model.layers.18.self_attn.o_proj",
      "model.layers.18.mlp.gate_proj",
      "model.layers.18.mlp.up_proj",
      "model.layers.18.mlp.down_proj",
      "model.layers.19.self_attn.q_proj",
      "model.layers.19.self_attn.k_proj",
      "model.layers.19.self_attn.v_proj",
      "model.layers.19.self_attn.o_proj",
      "model.layers.19.mlp.gate_proj",
      "model.layers.19.mlp.up_proj",
      "model.layers.19.mlp.down_proj",
      "model.layers.20.self_attn.q_proj",
      "model.layers.20.self_attn.k_proj",
      "model.layers.20.self_attn.v_proj",
      "model.layers.20.self_attn.o_proj",
      "model.layers.20.mlp.gate_proj",
      "model.layers.20.mlp.up_proj",
      "model.layers.20.mlp.down_proj",
      "model.layers.21.self_attn.q_proj",
      "model.layers.21.self_attn.k_proj",
      "model.layers.21.self_attn.v_proj",
      "model.layers.21.self_attn.o_proj",
      "model.layers.21.mlp.gate_proj",
      "model.layers.21.mlp.up_proj",
      "model.layers.21.mlp.down_proj",
      "model.layers.22.self_attn.q_proj",
      "model.layers.22.self_attn.k_proj",
      "model.layers.22.self_attn.v_proj",
      "model.layers.22.self_attn.o_proj",
      "model.layers.22.mlp.gate_proj",
      "model.layers.22.mlp.up_proj",
      "model.layers.22.mlp.down_proj",
      "model.layers.23.self_attn.q_proj",
      "model.layers.23.self_attn.k_proj",
      "model.layers.23.self_attn.v_proj",
      "model.layers.23.self_attn.o_proj",
      "model.layers.23.mlp.gate_proj",
      "model.layers.23.mlp.up_proj",
      "model.layers.23.mlp.down_proj",
      "model.layers.24.self_attn.q_proj",
      "model.layers.24.self_attn.k_proj",
      "model.layers.24.self_attn.v_proj",
      "model.layers.24.self_attn.o_proj",
      "model.layers.24.mlp.gate_proj",
      "model.layers.24.mlp.up_proj",
      "model.layers.24.mlp.down_proj",
      "model.layers.25.self_attn.q_proj",
      "model.layers.25.self_attn.k_proj",
      "model.layers.25.self_attn.v_proj",
      "model.layers.25.self_attn.o_proj",
      "model.layers.25.mlp.gate_proj",
      "model.layers.25.mlp.up_proj",
      "model.layers.25.mlp.down_proj",
      "model.layers.26.self_attn.q_proj",
      "model.layers.26.self_attn.k_proj",
      "model.layers.26.self_attn.v_proj",
      "model.layers.26.self_attn.o_proj",
      "model.layers.26.mlp.gate_proj",
      "model.layers.26.mlp.up_proj",
      "model.layers.26.mlp.down_proj",
      "model.layers.27.self_attn.q_proj",
      "model.layers.27.self_attn.k_proj",
      "model.layers.27.self_attn.v_proj",
      "model.layers.27.self_attn.o_proj",
      "model.layers.27.mlp.gate_proj",
      "model.layers.27.mlp.up_proj",
      "model.layers.27.mlp.down_proj"
    ],
    "skipped_layers": [
      "lm_head"
    ],
    "num_quantized": 196,
    "num_skipped": 1
  },
  "memory": {
    "total_params": 1543714304,
    "quantized_params": 1310195712,
    "unquantized_params": 233518592,
    "fp16_mb": 3087.428608,
    "quantized_mb": 1122.13504,
    "compression_ratio": 2.751387754543339
  },
  "experiments": {
    "baseline": {
      "precision": "fp16",
      "hellaswag_accuracy": 0.548,
      "wikitext_perplexity": 8.07165813446045
    },
    "rtn_per_tensor": {
      "precision": "int4 (per-tensor)",
      "hellaswag_accuracy": 0.264,
      "wikitext_perplexity": 10892309.0
    },
    "rtn_per_channel": {
      "precision": "int4 (per-channel)",
      "hellaswag_accuracy": 0.478,
      "wikitext_perplexity": 14.198935508728027
    },
    "absmax_per_channel": {
      "precision": "int4 absmax (per-channel)",
      "hellaswag_accuracy": 0.478,
      "wikitext_perplexity": 14.198935508728027
    },
    "gptq": {
      "precision": "int4 GPTQ",
      "hellaswag_accuracy": 0.496,
      "wikitext_perplexity": 13.93529987335205,
      "calibration_samples": 32,
      "calibration_seq_len": 256
    },
    "awq": {
      "precision": "int4 AWQ",
      "hellaswag_accuracy": 0.506,
      "wikitext_perplexity": 13.626382827758789,
      "calibration_samples": 32,
      "calibration_seq_len": 256
    },
    "bitsandbytes": {
      "precision": "4-bit bnb (NF4)",
      "hellaswag_accuracy": 0.516,
      "wikitext_perplexity": 8.682578086853027
    }
  }
}