{
  "model": "Qwen/Qwen2.5-1.5B",
  "bits": 8,
  "timestamp": "2025-12-27T06:31:49.507538",
  "layer_config": {
    "include_patterns": null,
    "exclude_patterns": [
      "embed_tokens",
      "lm_head",
      "norm"
    ],
    "quantized_layers": [
      "model.layers.0.self_attn.q_proj",
      "model.layers.0.self_attn.k_proj",
      "model.layers.0.self_attn.v_proj",
      "model.layers.0.self_attn.o_proj",
      "model.layers.0.mlp.gate_proj",
      "model.layers.0.mlp.up_proj",
      "model.layers.0.mlp.down_proj",
      "model.layers.1.self_attn.q_proj",
      "model.layers.1.self_attn.k_proj",
      "model.layers.1.self_attn.v_proj",
      "model.layers.1.self_attn.o_proj",
      "model.layers.1.mlp.gate_proj",
      "model.layers.1.mlp.up_proj",
      "model.layers.1.mlp.down_proj",
      "model.layers.2.self_attn.q_proj",
      "model.layers.2.self_attn.k_proj",
      "model.layers.2.self_attn.v_proj",
      "model.layers.2.self_attn.o_proj",
      "model.layers.2.mlp.gate_proj",
      "model.layers.2.mlp.up_proj",
      "model.layers.2.mlp.down_proj",
      "model.layers.3.self_attn.q_proj",
      "model.layers.3.self_attn.k_proj",
      "model.layers.3.self_attn.v_proj",
      "model.layers.3.self_attn.o_proj",
      "model.layers.3.mlp.gate_proj",
      "model.layers.3.mlp.up_proj",
      "model.layers.3.mlp.down_proj",
      "model.layers.4.self_attn.q_proj",
      "model.layers.4.self_attn.k_proj",
      "model.layers.4.self_attn.v_proj",
      "model.layers.4.self_attn.o_proj",
      "model.layers.4.mlp.gate_proj",
      "model.layers.4.mlp.up_proj",
      "model.layers.4.mlp.down_proj",
      "model.layers.5.self_attn.q_proj",
      "model.layers.5.self_attn.k_proj",
      "model.layers.5.self_attn.v_proj",
      "model.layers.5.self_attn.o_proj",
      "model.layers.5.mlp.gate_proj",
      "model.layers.5.mlp.up_proj",
      "model.layers.5.mlp.down_proj",
      "model.layers.6.self_attn.q_proj",
      "model.layers.6.self_attn.k_proj",
      "model.layers.6.self_attn.v_proj",
      "model.layers.6.self_attn.o_proj",
      "model.layers.6.mlp.gate_proj",
      "model.layers.6.mlp.up_proj",
      "model.layers.6.mlp.down_proj",
      "model.layers.7.self_attn.q_proj",
      "model.layers.7.self_attn.k_proj",
      "model.layers.7.self_attn.v_proj",
      "model.layers.7.self_attn.o_proj",
      "model.layers.7.mlp.gate_proj",
      "model.layers.7.mlp.up_proj",
      "model.layers.7.mlp.down_proj",
      "model.layers.8.self_attn.q_proj",
      "model.layers.8.self_attn.k_proj",
      "model.layers.8.self_attn.v_proj",
      "model.layers.8.self_attn.o_proj",
      "model.layers.8.mlp.gate_proj",
      "model.layers.8.mlp.up_proj",
      "model.layers.8.mlp.down_proj",
      "model.layers.9.self_attn.q_proj",
      "model.layers.9.self_attn.k_proj",
      "model.layers.9.self_attn.v_proj",
      "model.layers.9.self_attn.o_proj",
      "model.layers.9.mlp.gate_proj",
      "model.layers.9.mlp.up_proj",
      "model.layers.9.mlp.down_proj",
      "model.layers.10.self_attn.q_proj",
      "model.layers.10.self_attn.k_proj",
      "model.layers.10.self_attn.v_proj",
      "model.layers.10.self_attn.o_proj",
      "model.layers.10.mlp.gate_proj",
      "model.layers.10.mlp.up_proj",
      "model.layers.10.mlp.down_proj",
      "model.layers.11.self_attn.q_proj",
      "model.layers.11.self_attn.k_proj",
      "model.layers.11.self_attn.v_proj",
      "model.layers.11.self_attn.o_proj",
      "model.layers.11.mlp.gate_proj",
      "model.layers.11.mlp.up_proj",
      "model.layers.11.mlp.down_proj",
      "model.layers.12.self_attn.q_proj",
      "model.layers.12.self_attn.k_proj",
      "model.layers.12.self_attn.v_proj",
      "model.layers.12.self_attn.o_proj",
      "model.layers.12.mlp.gate_proj",
      "model.layers.12.mlp.up_proj",
      "model.layers.12.mlp.down_proj",
      "model.layers.13.self_attn.q_proj",
      "model.layers.13.self_attn.k_proj",
      "model.layers.13.self_attn.v_proj",
      "model.layers.13.self_attn.o_proj",
      "model.layers.13.mlp.gate_proj",
      "model.layers.13.mlp.up_proj",
      "model.layers.13.mlp.down_proj",
      "model.layers.14.self_attn.q_proj",
      "model.layers.14.self_attn.k_proj",
      "model.layers.14.self_attn.v_proj",
      "model.layers.14.self_attn.o_proj",
      "model.layers.14.mlp.gate_proj",
      "model.layers.14.mlp.up_proj",
      "model.layers.14.mlp.down_proj",
      "model.layers.15.self_attn.q_proj",
      "model.layers.15.self_attn.k_proj",
      "model.layers.15.self_attn.v_proj",
      "model.layers.15.self_attn.o_proj",
      "model.layers.15.mlp.gate_proj",
      "model.layers.15.mlp.up_proj",
      "model.layers.15.mlp.down_proj",
      "model.layers.16.self_attn.q_proj",
      "model.layers.16.self_attn.k_proj",
      "model.layers.16.self_attn.v_proj",
      "model.layers.16.self_attn.o_proj",
      "model.layers.16.mlp.gate_proj",
      "model.layers.16.mlp.up_proj",
      "model.layers.16.mlp.down_proj",
      "model.layers.17.self_attn.q_proj",
      "model.layers.17.self_attn.k_proj",
      "model.layers.17.self_attn.v_proj",
      "model.layers.17.self_attn.o_proj",
      "model.layers.17.mlp.gate_proj",
      "model.layers.17.mlp.up_proj",
      "model.layers.17.mlp.down_proj",
      "model.layers.18.self_attn.q_proj",
      "model.layers.18.self_attn.k_proj",
      "model.layers.18.self_attn.v_proj",
      "model.layers.18.self_attn.o_proj",
      "model.layers.18.mlp.gate_proj",
      "model.layers.18.mlp.up_proj",
      "model.layers.18.mlp.down_proj",
      "model.layers.19.self_attn.q_proj",
      "model.layers.19.self_attn.k_proj",
      "model.layers.19.self_attn.v_proj",
      "model.layers.19.self_attn.o_proj",
      "model.layers.19.mlp.gate_proj",
      "model.layers.19.mlp.up_proj",
      "model.layers.19.mlp.down_proj",
      "model.layers.20.self_attn.q_proj",
      "model.layers.20.self_attn.k_proj",
      "model.layers.20.self_attn.v_proj",
      "model.layers.20.self_attn.o_proj",
      "model.layers.20.mlp.gate_proj",
      "model.layers.20.mlp.up_proj",
      "model.layers.20.mlp.down_proj",
      "model.layers.21.self_attn.q_proj",
      "model.layers.21.self_attn.k_proj",
      "model.layers.21.self_attn.v_proj",
      "model.layers.21.self_attn.o_proj",
      "model.layers.21.mlp.gate_proj",
      "model.layers.21.mlp.up_proj",
      "model.layers.21.mlp.down_proj",
      "model.layers.22.self_attn.q_proj",
      "model.layers.22.self_attn.k_proj",
      "model.layers.22.self_attn.v_proj",
      "model.layers.22.self_attn.o_proj",
      "model.layers.22.mlp.gate_proj",
      "model.layers.22.mlp.up_proj",
      "model.layers.22.mlp.down_proj",
      "model.layers.23.self_attn.q_proj",
      "model.layers.23.self_attn.k_proj",
      "model.layers.23.self_attn.v_proj",
      "model.layers.23.self_attn.o_proj",
      "model.layers.23.mlp.gate_proj",
      "model.layers.23.mlp.up_proj",
      "model.layers.23.mlp.down_proj",
      "model.layers.24.self_attn.q_proj",
      "model.layers.24.self_attn.k_proj",
      "model.layers.24.self_attn.v_proj",
      "model.layers.24.self_attn.o_proj",
      "model.layers.24.mlp.gate_proj",
      "model.layers.24.mlp.up_proj",
      "model.layers.24.mlp.down_proj",
      "model.layers.25.self_attn.q_proj",
      "model.layers.25.self_attn.k_proj",
      "model.layers.25.self_attn.v_proj",
      "model.layers.25.self_attn.o_proj",
      "model.layers.25.mlp.gate_proj",
      "model.layers.25.mlp.up_proj",
      "model.layers.25.mlp.down_proj",
      "model.layers.26.self_attn.q_proj",
      "model.layers.26.self_attn.k_proj",
      "model.layers.26.self_attn.v_proj",
      "model.layers.26.self_attn.o_proj",
      "model.layers.26.mlp.gate_proj",
      "model.layers.26.mlp.up_proj",
      "model.layers.26.mlp.down_proj",
      "model.layers.27.self_attn.q_proj",
      "model.layers.27.self_attn.k_proj",
      "model.layers.27.self_attn.v_proj",
      "model.layers.27.self_attn.o_proj",
      "model.layers.27.mlp.gate_proj",
      "model.layers.27.mlp.up_proj",
      "model.layers.27.mlp.down_proj"
    ],
    "skipped_layers": [
      "lm_head"
    ],
    "num_quantized": 196,
    "num_skipped": 1
  },
  "memory": {
    "total_params": 1543714304,
    "quantized_params": 1310195712,
    "unquantized_params": 233518592,
    "fp16_mb": 3087.428608,
    "quantized_mb": 1777.232896,
    "compression_ratio": 1.7372110402349878
  },
  "experiments": {
    "baseline": {
      "precision": "fp16",
      "hellaswag_accuracy": 0.546,
      "wikitext_perplexity": 8.07194995880127
    },
    "rtn_per_tensor": {
      "precision": "int8 (per-tensor)",
      "hellaswag_accuracy": 0.54,
      "wikitext_perplexity": 8.271353721618652
    },
    "rtn_per_channel": {
      "precision": "int8 (per-channel)",
      "hellaswag_accuracy": 0.548,
      "wikitext_perplexity": 8.078725814819336
    },
    "absmax_per_channel": {
      "precision": "int8 absmax (per-channel)",
      "hellaswag_accuracy": 0.548,
      "wikitext_perplexity": 8.078725814819336
    }
  }
}